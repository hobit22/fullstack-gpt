{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Introduction\\nLangChain is a framework for developing applications powered by language models. It enables applications that:\\n\\nAre context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.)\\nReason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)\\nThis framework consists of several parts.\\n\\nLangChain Libraries: The Python and JavaScript libraries. Contains interfaces and integrations for a myriad of components, a basic run time for combining these components into chains and agents, and off-the-shelf implementations of chains and agents.\\nLangChain Templates: A collection of easily deployable reference architectures for a wide variety of tasks.\\nLangServe: A library for deploying LangChain chains as a REST API.\\nLangSmith: A developer platform that lets you debug, test, evaluate, and monitor chains built on any LLM framework and seamlessly integrates with LangChain.\\nLangChain Diagram\\n\\nTogether, these products simplify the entire application lifecycle:\\n\\nDevelop: Write your applications in LangChain/LangChain.js. Hit the ground running using Templates for reference.\\nProductionize: Use LangSmith to inspect, test and monitor your chains, so that you can constantly improve and deploy with confidence.\\nDeploy: Turn any chain into an API with LangServe.\\nLangChain Libraries\\nThe main value props of the LangChain packages are:\\n\\nComponents: composable tools and integrations for working with language models. Components are modular and easy-to-use, whether you are using the rest of the LangChain framework or not\\nOff-the-shelf chains: built-in assemblages of components for accomplishing higher-level tasks\\nOff-the-shelf chains make it easy to get started. Components make it easy to customize existing chains and build new ones.\\n\\nGet started\\nHere’s how to install LangChain, set up your environment, and start building.\\n\\nWe recommend following our Quickstart guide to familiarize yourself with the framework by building your first LangChain application.\\n\\nRead up on our Security best practices to make sure you're developing safely with LangChain.\\n\\nNOTE\\nThese docs focus on the Python LangChain library. Head here for docs on the JavaScript LangChain library.\\n\\nLangChain Expression Language (LCEL)\\nLCEL is a declarative way to compose chains. LCEL was designed from day 1 to support putting prototypes in production, with no code changes, from the simplest “prompt + LLM” chain to the most complex chains.\\n\\nOverview: LCEL and its benefits\\nInterface: The standard interface for LCEL objects\\nHow-to: Key features of LCEL\\nCookbook: Example code for accomplishing common tasks\\nModules\\nLangChain provides standard, extendable interfaces and integrations for the following modules:\\n\\nModel I/O\\nInterface with language models\\n\\nRetrieval\\nInterface with application-specific data\\n\\nAgents\\nLet models choose which tools to use given high-level directives\\n\\nExamples, ecosystem, and resources\\nUse cases\\nWalkthroughs and techniques for common end-to-end use cases, like:\\n\\nDocument question answering\\nChatbots\\nAnalyzing structured data\\nand much more...\\nIntegrations\\nLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of integrations.\\n\\nGuides\\nBest practices for developing with LangChain.\\n\\nAPI reference\\nHead to the reference section for full documentation of all classes and methods in the LangChain and LangChain Experimental Python packages.\\n\\nDeveloper's guide\\nCheck out the developer's guide for guidelines on contributing and help getting your dev environment set up.\\n\\nCommunity\\nHead to the Community navigator to find places to ask questions, share feedback, meet other developers, and dream about the future of LLM’s.\", metadata={'source': './files/introduction.txt'})]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\n",
    "    file_path=\"./files/introduction.txt\",\n",
    "    encoding='UTF-8'\n",
    ")\n",
    "\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "\n",
    "# UnstructuredFileLoader 는 txt, ppt, html, pdfs, images 등등 읽어올 수 있다.\n",
    "# https://python.langchain.com/docs/integrations/document_loaders/unstructured_file\n",
    "loader = UnstructuredFileLoader(\n",
    "    file_path=\"./files/xxx.pdf\",\n",
    "    encoding='UTF-8'\n",
    ")\n",
    "\n",
    "loader.load()\n",
    "\n",
    "len(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\n",
    "    file_path=\"./files/0_1_introduction.txt\",\n",
    "    encoding='UTF-8'\n",
    ")\n",
    "\n",
    "loader.load_and_split(text_splitter=splitter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\n",
    "    file_path=\"./files/0_1_introduction.txt\",\n",
    "    encoding='UTF-8'\n",
    ")\n",
    "\n",
    "len(loader.load_and_split(text_splitter=splitter))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
